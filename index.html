<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>咖啡猫的网络日志</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="用于记录学习心得，包含java,hadoop,spring,javascript,web,大数据,big data,spark相关内容">
<meta name="keywords" content="java,hadoop,spring,javascript,web,大数据,big data,spark">
<meta property="og:type" content="website">
<meta property="og:title" content="咖啡猫的网络日志">
<meta property="og:url" content="https:&#x2F;&#x2F;yyddbull.github.io&#x2F;index.html">
<meta property="og:site_name" content="咖啡猫的网络日志">
<meta property="og:description" content="用于记录学习心得，包含java,hadoop,spring,javascript,web,大数据,big data,spark相关内容">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/coffeecat/atom.xml" title="咖啡猫的网络日志" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/coffeecat/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/coffeecat/" id="logo">咖啡猫的网络日志</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/coffeecat/">首页</a>
        
          <a class="main-nav-link" href="/coffeecat/archives">归档</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/coffeecat/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://yyddbull.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/coffeecat/2019/10/29/hello-world/" class="article-date">
  <time datetime="2019-10-29T02:51:42.922Z" itemprop="datePublished">2019-10-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/coffeecat/categories/%E5%85%B6%E4%BB%96/">其他</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/coffeecat/2019/10/29/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://yyddbull.github.io/2019/10/29/hello-world/" data-id="ck2czn5rk0000pj06f2xz9y4x" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-spark-learning2" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/coffeecat/2019/10/27/spark-learning2/" class="article-date">
  <time datetime="2019-10-27T03:54:12.000Z" itemprop="datePublished">2019-10-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/coffeecat/categories/spark/">spark</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/coffeecat/2019/10/27/spark-learning2/">Spark工作机制（二）</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p> 了解了RDD概念后，介绍下Spark的工作机制： </p>
<h1 id="1、惰性计算"><a href="#1、惰性计算" class="headerlink" title="1、惰性计算"></a><strong>1、惰性计算</strong></h1><p>首先，值得一提的是，Spark的RDD的Transformation操作都是惰性计算的，也就是只有在执行Action操作的时候才会真正开始计算。转化操作不会立刻执行，而是在内部记录下所要执行的操作的相关标识，等到了Action操作后再执行，Spark的这一个特性也叫做<strong>惰性计算</strong>。</p>
<p>这样有什么好处呢？举个例子，假如textFile读取文件数据，通过flatMap按照空格分隔后，再用fitler方法根据关键字过滤，最后调用first()返回数据集第一个元素，如果中途每个操作都要产生新的 RDD,那势必会浪费很多内存空间，所以Spark在调用first操作的时候，才会正常的执行计算，因此，我们调试Spark程序时，当断点打在Transformation操作的函数中时，有时候会无法进入，只有当调用了Action操作时，才会真正执行。</p>
<h1 id="2、Spark应用执行组件"><a href="#2、Spark应用执行组件" class="headerlink" title="2、Spark应用执行组件"></a><strong>2、Spark应用执行组件</strong></h1><p>Spark应用的运行方式分为Cluster模式和Client模式，其中Client模式是指Driver Program在任务提交机上执行，适用于交互和调试，也就是希望快速看到计算结果；而Cluster模式运行在ApplicationMaster中，一般应用在生产过程中。</p>
<p>这里先解释一些涉及的基本组件的概念：</p>
<p>Application：用户自定义的Spark程序，包含1个Driver Program和若干个Executor进程。</p>
<p>Driver Program：运行Application的main()函数并且创建SparkContext，是应用的主控进程，负责应用的解析、切分Stage并调度Task到Executor进程上执行。</p>
<p>SparkContext：是spark应用程序的入口，负责调度各个运算资源，协调各个work node上的Executor。</p>
<p>Executor：是Application运行在work node上的一个进程，负责运行Task，一般每个Application都有各自独立的executors，不同application的executor若不通过外部存储，是无法进行数据交互的。</p>
<p>Master：集群中的含有Master进程的节点，用于控制、管理和监督整个spark集群。</p>
<p>Client：客户端节点，负责客户端进程，提交job到master。</p>
<p>Work Node：集群的工作节点，接受Master的指令，运行Application的代码，并向Master汇报进度。</p>
<p>Task：任务，一般一个RDD分区对应一个Task，是单个分区上最小的处理流程单元。</p>
<p>TaskSet：一组关联的，但相互之间没有Shuffle依赖关系的Task集合。</p>
<p>Stage：一个taskSet对应的调度阶段，每个job会根据RDD的宽依赖关系被切分很多Stage，每个stage都包含 一个TaskSet。</p>
<p>Job：由Spark Action操作触发的作业。</p>
<p>Spark几个运行组件的关系如图1所示：</p>
<h1 id="3、Spark应用执行流程"><a href="#3、Spark应用执行流程" class="headerlink" title="3、Spark应用执行流程"></a><strong>3、Spark应用执行流程</strong></h1><p>Spark的应用提交有2种模式，一个是Driver进程在客户端运行，一个是Master节点指定Driver进程在某个Work节点运行。</p>
<p><strong>（1）Driver进程在客户端运行</strong></p>
<p>执行流程如图2所示，</p>
<p><img src="/coffeecat/2019/10/27/spark-learning2/driver_client.png" alt></p>
<ul>
<li>Client端启动Driver进程，在Driver中启动或实例化DAGScheduler等组件。</li>
<li>Worker向Master注册，Master通过指令让Worker启动Executor。</li>
<li>Worker收到指令后创建ExecutorRunner线程，ExecutorRunner线程内部启动ExecutorBackend进程</li>
<li>ExecutorBackend启动后，向Client端Driver进程内的SchedulerBackend注册,这样Dirver进程就可以发现计算资源了。</li>
<li>Driver的DAGScheduler解析应用中的RDD DAG并生成相应的Stage，每个Stage包含的TaskSet通过TaskScheduler分配给Executor，在Exectutor内部启动线程池并行化执行Task</li>
<li>当所有Stage被执行完了之后，各个Worker汇报给Driver，同时释放资源，Driver向Master汇报，同时由于Driver在Client上，Clinet也知道应用的执行进度。</li>
</ul>
<p><strong>（2）Driver进程在Work节点运行</strong></p>
<p>执行流程如图3所示，</p>
<p><img src="/coffeecat/2019/10/27/spark-learning2/driver_worker.png" alt></p>
<ul>
<li>客户端提交应用程序给Master</li>
<li>Master调度应用，指定一个Worker节点启动Driver。</li>
<li>Worker接收到Master命令后创建RriverRunner线程，在DriverRunner线程内创建SchedulerBackend进程，Dirver充当整个作业的主控进程。</li>
<li>Master指定其他Worker节点启动Exeuctor，Worker创建ExecutorRunner线程，启动ExecutorBackend进程，剩下流程与上面类似，不再赘述。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://yyddbull.github.io/2019/10/27/spark-learning2/" data-id="ck2czn5rr0004pj065c318ht3" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/coffeecat/tags/spark-driver-%E6%83%B0%E6%80%A7%E8%AE%A1%E7%AE%97-%E6%89%A7%E8%A1%8C%E6%9C%BA%E5%88%B6-spark-application/" rel="tag">spark,driver,惰性计算,执行机制,spark application</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-spark-learning1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/coffeecat/2019/10/25/spark-learning1/" class="article-date">
  <time datetime="2019-10-25T05:52:09.000Z" itemprop="datePublished">2019-10-25</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/coffeecat/categories/spark/">spark</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/coffeecat/2019/10/25/spark-learning1/">Spark工作机制（一）</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>要了解Spark工作机制，首先要知道几个概念，第一个就是RDD：</p>
<h1 id="1、什么是RDD"><a href="#1、什么是RDD" class="headerlink" title="1、什么是RDD"></a>1、什么是RDD</h1><p>RDD（Resilient Distributed Datasets） 是 Spark 的核心概念，中文名是弹性数据集，通俗的讲可以理解为是一种抽象的大规模数据集合，或者是一个大的数组，这个数组是分布在集群上的，Spark会在这个数据集合上做一系列的数据处理、计算，然后产生新的RDD，直到最后得到计算结果。</p>
<p>至于为什么叫弹性数据集，弹性如何解释？这里是指在任何时候都能进行重算。举个例子，当集群中的一台节点故障导致RDD丢失后，Spark还可以重新计算出这部分的分区的数据，所以，RDD是一种天生具有容错机制的特殊集合，不需要通过数据冗余的方式（比如检查点）实现容错，对用户来说，感觉不到这部分的内容曾经丢失，所以RDD数据集就像一个海绵一样，无论如何挤压都是完整的。</p>
<h1 id="2、RDD的特性"><a href="#2、RDD的特性" class="headerlink" title="2、RDD的特性"></a><strong>2、RDD的特性</strong></h1><p>Spark官网对RDD的描述：</p>
<ul>
<li>A list of partitions</li>
<li>A function for computing each split</li>
<li>A list of dependencies on other RDDs</li>
<li>Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)</li>
<li>Optionally, a list of preferred locations to compute each split on (e.g. block locations for an HDFS file)</li>
</ul>
<p>解释如下：</p>
<ul>
<li>是一组分区（partition），类似hadoop，能够被切分，从而实现并行计算，如图1所示，RDD1中有3个区分（p1,p3,p4），分别存储在3个节点上</li>
<li>有一个函数计算分片，每个RDD都会实现compute函数,对每个分区内的数据进行计算</li>
<li>依赖其他RDD的列表，例如由于RDD的转换生成一个新的RDD，这样RDD之间就会形成类似于流水线一样的前后依赖关系</li>
<li>可选，一个分区函数。Spark中有HashPartitioner和RangePartitioner。只有对于于key-value的RDD，才会有Partitioner，非key-value的RDD的Parititioner的值是None</li>
<li>可选，一个存储存取每个Partition的优先位置的列表。对于HDFS文件来说，这个列表保存的就是每个Partition所在块的位置</li>
</ul>
<p><img src="/coffeecat/2019/10/25/spark-learning1/rdd_deploy.png" alt></p>
<h1 id="3、RDD的操作分类"><a href="#3、RDD的操作分类" class="headerlink" title="3、RDD的操作分类"></a><strong>3、RDD的操作分类</strong></h1><p> RDD有2种操作类型： </p>
<ul>
<li>转换(transformations) ：从已经存在的数据集中创建一个新的数据集，会创建一个新的RDD，例如map操作，会针对将数据集的每个元素传给函数处理，并生成一个新的RDD</li>
<li>动作(actions) ：在数据集上进行计算之后返回一个值到驱动程序，例如reduce动作，使用函数聚合RDD所有元素，并将结果返回给驱动程序</li>
</ul>
<p>常用的Transformation如下：</p>
<ul>
<li>map(func)：返回一个新的分布式数据集，该数据集由每一个输入元素经过func函数转换后组成</li>
<li>fitler(func)：返回一个新的数据集，该数据集由经过func函数计算后返回值为true的输入元素组成</li>
<li>flatMap(func)：类似于map，但是每一个输入元素可以被映射为0或多个输出元素（因此func返回一个序列，而不是单一元素）</li>
<li>mapPartitions(func)：类似于map，但独立地在RDD上每一个分片上运行，因此在类型为T的RDD上运行时，func函数类型必须是Iterator[T]=&gt;Iterator[U]</li>
<li>mapPartitionsWithSplit(func)：类似于mapPartitons，但func带有一个整数参数表示分片的索引值。因此在类型为T的RDD上运行时，func函数类型必须是(Int,Iterator[T])=&gt;Iterator[U]</li>
<li>sample(withReplacement,fraction,seed)：根据fraction指定的比例对数据进行采样，可以选择是否用随机数进行替换，seed用于随机数生成器种子</li>
<li>union(otherDataSet)：返回一个新数据集，新数据集是由原数据集和参数数据集联合而成</li>
<li>distinct([numTasks])：返回一个包含原数据集中所有不重复元素的新数据集</li>
<li>groupByKey([numTasks])：在一个(K,V)数据集上调用，返回一个(K,Seq[V])对的数据集。注意默认情况下，只有8个并行任务来操作，但是可以传入一个可选的numTasks参数来改变它</li>
<li>reduceByKey(func,[numTasks])：在一个(K,V)对的数据集上调用，返回一个(K,V)对的数据集，使用指定的reduce函数，将相同的key的值聚合到一起。与groupByKey类似，reduceByKey任务的个数是可以通过第二个可选参数来设置的</li>
<li>sortByKey([[ascending],numTasks])：在一个(K,V)对的数据集上调用，K必须实现Ordered接口，返回一个按照Key进行排序的(K,V)对数据集。升序或降序由ascending布尔参数决定</li>
<li>join(otherDataset0,[numTasks])：在类型为(K,V)和(K,W)数据集上调用，返回一个相同的key对应的所有元素在一起的(K,(V,W))数据集</li>
<li>cogroup(otherDataset,[numTasks])：在类型为(K,V)和(K,W)数据集上调用，返回一个(K,Seq[V],Seq[W])元祖的数据集。这个操作也可以称为groupwith</li>
<li>cartesain(ohterDataset)：笛卡尔积，在类型为T和U类型的数据集上调用，返回一个(T,U)对数据集(两两的元素对)</li>
</ul>
<p>常用的Action如下：</p>
<ul>
<li>reduce(func)：通过函数func(接收两个参数，返回一个参数)聚集数据集中的所有元素。这个功能必须可交换且可关联的，从而可以正确的并行运行</li>
<li>collect()：在驱动程序中，以数组形式返回数据集中的所有元素。通常在使用filter或者其他操作返回一个足够小的数据子集后再使用会比较有用</li>
<li>count()：返回数据集元素个数</li>
<li>first()：返回数据集第一个元素(类似于take(1))</li>
<li>take(n)：返回一个由数据集前n个元素组成的数组，注意 这个操作目前并非并行执行，而是由驱动程序计算所有的元素</li>
<li>takeSample(withReplacement,num,seed)：返回一个数组，该数组由从数据集中随机采样的num个元素组成，可以选择是否由随机数替换不足的部分，seed用户指定随机数生成器种子</li>
<li>saveAsTextFile(path)：将数据集的元素以textfile的形式保存到本地文件系统–HDFS或者任何其他Hadoop支持的文件系统。对于每个元素，Spark将会调用toString方法，将它转换为文件中的文本行</li>
<li>saveAsSequenceFile(path)：将数据集中的元素以Hadoop sequencefile的格式保存到指定的目录下，可以是本地系统、HDFS或者任何其他的Hadoop支持的文件系统。这个只限于由key-value对组成，并实现了Hadoop的Writable接口，或者可以隐式的转换为Writable的RDD(Spark包括了基本类型转换，例如Int、Double、String等)</li>
<li>countByKey()：对(K,V)类型的RDD有效，返回一个(K,Int)对的map，表示每一个key对应的元素个数</li>
<li>foreach(func)：在数据集的每一个元素上，运行函数func进行更新。通常用于边缘效果，例如更新一个叠加器，或者和外部存储系统进行交互，如HBase</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://yyddbull.github.io/2019/10/25/spark-learning1/" data-id="ck2czn5ro0002pj061wutgxk9" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/coffeecat/tags/spark-%E5%A4%A7%E6%95%B0%E6%8D%AE-big-data-rdd-%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/" rel="tag">spark,大数据,big data,rdd,工作机制</a></li></ul>

    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/coffeecat/categories/spark/">spark</a></li><li class="category-list-item"><a class="category-list-link" href="/coffeecat/categories/%E5%85%B6%E4%BB%96/">其他</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/coffeecat/tags/spark-driver-%E6%83%B0%E6%80%A7%E8%AE%A1%E7%AE%97-%E6%89%A7%E8%A1%8C%E6%9C%BA%E5%88%B6-spark-application/" rel="tag">spark,driver,惰性计算,执行机制,spark application</a></li><li class="tag-list-item"><a class="tag-list-link" href="/coffeecat/tags/spark-%E5%A4%A7%E6%95%B0%E6%8D%AE-big-data-rdd-%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/" rel="tag">spark,大数据,big data,rdd,工作机制</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/coffeecat/tags/spark-driver-%E6%83%B0%E6%80%A7%E8%AE%A1%E7%AE%97-%E6%89%A7%E8%A1%8C%E6%9C%BA%E5%88%B6-spark-application/" style="font-size: 10px;">spark,driver,惰性计算,执行机制,spark application</a> <a href="/coffeecat/tags/spark-%E5%A4%A7%E6%95%B0%E6%8D%AE-big-data-rdd-%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/" style="font-size: 10px;">spark,大数据,big data,rdd,工作机制</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/coffeecat/archives/2019/10/">十月 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/coffeecat/2019/10/29/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/coffeecat/2019/10/27/spark-learning2/">Spark工作机制（二）</a>
          </li>
        
          <li>
            <a href="/coffeecat/2019/10/25/spark-learning1/">Spark工作机制（一）</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 咖啡猫<br>
      Powered by <a href="http://hexo.io/" target="_blank">coffeecat</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/coffeecat/" class="mobile-nav-link">首页</a>
  
    <a href="/coffeecat/archives" class="mobile-nav-link">归档</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/coffeecat/fancybox/jquery.fancybox.css">
  <script src="/coffeecat/fancybox/jquery.fancybox.pack.js"></script>


<script src="/coffeecat/js/script.js"></script>



  </div>
</body>
</html>